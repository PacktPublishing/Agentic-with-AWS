{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8208f7d6-391d-4054-9e67-ac0f85878dcd",
   "metadata": {},
   "source": [
    "# LangGraph with AgentCore Memory Checkpointer (Short term memory)\n",
    "\n",
    "## Introduction\n",
    "This notebook demonstrates how to integrate Amazon Bedrock AgentCore Memory capabilities with LangGraph using the **AgentCoreMemorySaver** checkpointer. We'll focus on **short-term memory** persistence across conversation turns - allowing an agent to maintain running context and build upon previous calculations through automatic state checkpointing.\n",
    "\n",
    "## Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                          |\n",
    "|:--------------------|:---------------------------------------------------------------------------------|\n",
    "| Tutorial type       | Short Term Conversational                                                        |\n",
    "| Agent usecase       | Multi-step Math Calculations                                                     |\n",
    "| Agentic Framework   | Langgraph                                                                        |\n",
    "| LLM model           | Anthropic Claude Haiku 4.5                                                      |\n",
    "| Tutorial components | AgentCore Short-term Memory, Langgraph Checkpointer, Math Tools                |\n",
    "| Example complexity  | Beginner                                                                         |\n",
    "\n",
    "You'll learn to:\n",
    "- Create a memory checkpointer with AgentCore Memory for automatic state persistence\n",
    "- Use LangGraph's built-in checkpointing system with AgentCore Memory backend\n",
    "- Maintain conversation context across multiple interactions\n",
    "- Inspect and manage conversation state and history\n",
    "\n",
    "### Scenario Context\n",
    "\n",
    "In this example, we'll create a \"**Math Agent**\" that can perform multi-step mathematical calculations. Unlike simple one-off interactions, this agent uses AgentCore Memory's checkpointing capabilities to maintain running context, allowing it to build upon previous calculations and remember the conversation flow across multiple turns.\n",
    "\n",
    "## Architecture\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture.png\" width=\"65%\" />\n",
    "</div>\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- AWS account with appropriate permissions\n",
    "- AWS IAM role with appropriate permissions for AgentCore Memory\n",
    "- Access to Amazon Bedrock models\n",
    "\n",
    "### How the Integration Works\n",
    "\n",
    "The integration between LangGraph and AgentCore Memory involves:\n",
    "\n",
    "1. Using AgentCore Memory as a checkpointer backend for LangGraph state persistence\n",
    "2. Automatic saving and loading of conversation state at each step\n",
    "3. Support for multiple concurrent sessions and actors\n",
    "\n",
    "This approach provides seamless state management without requiring manual memory operations, creating a more maintainable and scalable agent architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6acbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d5034-c019-4c2d-897f-0f735020cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eff8706-6715-4981-983b-934561ee0a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "# Import LangGraph and LangChain components\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc12fd92-b84a-4d2f-b96d-83d3da08bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AgentCoreMemorySaver that we will use as a checkpointer\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from langgraph_checkpoint_aws import AgentCoreMemorySaver\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "\n",
    "region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "logging.getLogger(\"math-agent\").setLevel(logging.DEBUG)\n",
    "# Create or get the memory resource\n",
    "memory_name = \"MathLanggraphAgent\"\n",
    "client = MemoryClient(region_name=region)\n",
    "memory = client.create_memory(name=memory_name)\n",
    "memory_id = memory['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56f7566-980e-48b2-892d-ac7c3e334717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLanggraphAgent-7b2X8M8Rr0\n"
     ]
    }
   ],
   "source": [
    "print(memory_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d91a14-541c-426c-a52c-5fdcf29f8953",
   "metadata": {},
   "source": [
    "### AgentCore Memory Configuration\n",
    "\n",
    "Now let's configure our AgentCore Memory checkpointer and initialize the LLM:\n",
    "\n",
    "- `memory_id` corresponds to our AgentCore Memory resource where checkpoints will be stored\n",
    "- `region` specifies the AWS region for our resources\n",
    "- `MODEL_ID` defines the Bedrock model that will power our LangGraph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "226d094c-a05d-4f88-851d-cc42ff63ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"global.anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
    "\n",
    "# Initialize checkpointer for state persistence\n",
    "checkpointer = AgentCoreMemorySaver(memory_id, region_name=region)\n",
    "\n",
    "# Initialize LLM\n",
    "llm = init_chat_model(MODEL_ID, model_provider=\"bedrock_converse\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c77aa-4b19-49a5-af3c-db2b4798384b",
   "metadata": {},
   "source": [
    "### Mathematical Tools\n",
    "\n",
    "Let's define the mathematical tools our agent will use. For this demonstration, we'll provide two simple operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd81ba1c-3fb8-474c-ae40-0ee7c62ca234",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int):\n",
    "    \"\"\"Add two integers and return the result\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply two integers and return the result\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b6e3f-8b41-4c07-8a32-680666b2661e",
   "metadata": {},
   "source": [
    "### LangGraph Agent Implementation\n",
    "\n",
    "Now let's create our agent using LangGraph's `create_react_agent` builder with our AgentCore Memory checkpointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a116a57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274608/3477183685.py:1: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  graph = create_react_agent(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f28a5aaf3b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=\"You are a helpful assistant\",\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cbbb3a-f85c-42f5-bbfb-40f5f6b8b48c",
   "metadata": {},
   "source": [
    "## Step 4: Run the LangGraph Agent\n",
    "We can now run the agent with our AgentCore Memory checkpointer integration.\n",
    "\n",
    "### Configuration Setup\n",
    "In LangGraph, config is a `RuntimeConfig` that contains attributes that are necessary at invocation time, for example user IDs or session IDs. You can read additional documentation here: [https://langchain-ai.github.io/langgraphjs/how-tos/configuration/](https://langchain-ai.github.io/langgraphjs/how-tos/configuration/)\n",
    "\n",
    "For the AgentCore Memory checkpointer (`AgentCoreMemorySaver`), we NEED to specify:\n",
    "- `thread_id`: Maps to AgentCore session_id (unique conversation thread)\n",
    "- `actor_id`: Maps to AgentCore actor_id (user, agent, or any other identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "859fee36-1eff-4713-9c3b-387b702c0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-1\", # REQUIRED: This maps to Bedrock AgentCore session_id under the hood\n",
    "        \"actor_id\": \"react-agent-1\", # REQUIRED: This maps to Bedrock AgentCore actor_id under the hood\n",
    "    }\n",
    "}\n",
    "\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What is 1337 times 515321? Then add 412 and return the value to me.\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96044de0-2d32-4811-ac30-43f4416f4303",
   "metadata": {},
   "source": [
    "#### Congratulations! Your Agent is ready!!\n",
    "\n",
    "### Let's test the Agent\n",
    "\n",
    "Let's run our first calculation to see the agent in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2bc4869-58cd-4914-9a7a-8d39ecd16226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=[{'type': 'text', 'text': \"I'll calculate 1337 times 515321, then add 412 to the result.\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 1337, 'b': 515321}, 'id': 'tooluse_PnzIG9OF7Oh5v9I17G8rdR'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'cb92b9a0-735b-4016-9527-5d830b7cab20', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Feb 2026 18:23:15 GMT', 'content-type': 'application/json', 'content-length': '501', 'connection': 'keep-alive', 'x-amzn-requestid': 'cb92b9a0-735b-4016-9527-5d830b7cab20'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1723]}, 'model_name': 'global.anthropic.claude-haiku-4-5-20251001-v1:0'}, id='run--afb0f729-ad6e-4190-b045-26064c597a5d-0', tool_calls=[{'name': 'multiply', 'args': {'a': 1337, 'b': 515321}, 'id': 'tooluse_PnzIG9OF7Oh5v9I17G8rdR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 665, 'output_tokens': 92, 'total_tokens': 757, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='688984177', name='multiply', id='792dbeba-245a-4fbd-8a3d-ba52631dcaab', tool_call_id='tooluse_PnzIG9OF7Oh5v9I17G8rdR')]}}\n",
      "{'agent': {'messages': [AIMessage(content=[{'type': 'text', 'text': \"Now I'll add 412 to that result:\"}, {'type': 'tool_use', 'name': 'add', 'input': {'a': 688984177, 'b': 412}, 'id': 'tooluse_fBlcSdeqgUpu3KBel5HeOw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '316c2317-d9b0-46a9-af10-ff452d2eed9a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Feb 2026 18:23:17 GMT', 'content-type': 'application/json', 'content-length': '469', 'connection': 'keep-alive', 'x-amzn-requestid': '316c2317-d9b0-46a9-af10-ff452d2eed9a'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1283]}, 'model_name': 'global.anthropic.claude-haiku-4-5-20251001-v1:0'}, id='run--23e5703f-6a7e-4640-ae5f-e2d69b78f7ff-0', tool_calls=[{'name': 'add', 'args': {'a': 688984177, 'b': 412}, 'id': 'tooluse_fBlcSdeqgUpu3KBel5HeOw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 772, 'output_tokens': 82, 'total_tokens': 854, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='688984589', name='add', id='4a11daf7-cf2e-474c-a65c-e17690fe100e', tool_call_id='tooluse_fBlcSdeqgUpu3KBel5HeOw')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The answer is **688,984,589**.\\n\\nTo break it down:\\n- 1337 × 515,321 = 688,984,177\\n- 688,984,177 + 412 = **688,984,589**', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'a337a0bb-c178-4dfe-b8f9-6d022a21ad45', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Feb 2026 18:23:20 GMT', 'content-type': 'application/json', 'content-length': '438', 'connection': 'keep-alive', 'x-amzn-requestid': 'a337a0bb-c178-4dfe-b8f9-6d022a21ad45'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [3324]}, 'model_name': 'global.anthropic.claude-haiku-4-5-20251001-v1:0'}, id='run--3fb4a393-ee48-4a27-a79d-f73bcad5df53-0', usage_metadata={'input_tokens': 869, 'output_tokens': 59, 'total_tokens': 928, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d28db8-c9cc-4fa1-922d-89476e9f71c5",
   "metadata": {},
   "source": [
    "### Inspecting Agent State\n",
    "\n",
    "Let's examine the current conversation state stored in AgentCore Memory. The checkpointer automatically saves and retrieves state for our actor and session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60042ec5-cd64-48f3-bd7d-cb7ca9e21b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: What is 1337 times 515321? Then add 412 and return the value to me.\n",
      "=========================================\n",
      "ai: I'll calculate 1337 times 515321, then add 412 to the result.\n",
      "=========================================\n",
      "tool: 688984177\n",
      "=========================================\n",
      "ai: Now I'll add 412 to that result:\n",
      "=========================================\n",
      "tool: 688984589\n",
      "=========================================\n",
      "ai: The answer is **688,984,589**.\n",
      "\n",
      "To break it down:\n",
      "- 1337 × 515,321 = 688,984,177\n",
      "- 688,984,177 + 412 = **688,984,589**\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "for message in graph.get_state(config).values.get(\"messages\"):\n",
    "    print(f\"{message.type}: {message.text()}\")\n",
    "    print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0c9bd-6fb6-467d-b51a-84696238b4fa",
   "metadata": {},
   "source": [
    "### Viewing Checkpoint History\n",
    "\n",
    "Let's explore the checkpoint history to see how the agent's state evolved during execution.  Checkpoints are listed in reverse chronological order (most recent appear first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2232c2b-154d-4b50-93b0-925eb88e67c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding placeholder ToolMessage for orphaned tool_call 'add' (id: tooluse_fBlcSdeqgUpu3KBel5HeOw) during checkpoint load\n",
      "Adding placeholder ToolMessage for orphaned tool_call 'multiply' (id: tooluse_PnzIG9OF7Oh5v9I17G8rdR) during checkpoint load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Checkpoint ID: 1f10c2db-cd48-68d9-8005-1f1b2397cb80) # of messages in state: 6\n",
      "(Checkpoint ID: 1f10c2db-ad7e-69b9-8004-8fbd9385f8ed) # of messages in state: 5\n",
      "(Checkpoint ID: 1f10c2db-ad71-6b23-8003-20284a8b8c0a) # of messages in state: 5\n",
      "(Checkpoint ID: 1f10c2db-a11d-6fb6-8002-9289b68df732) # of messages in state: 3\n",
      "(Checkpoint ID: 1f10c2db-a10f-6d6d-8001-29782b219b51) # of messages in state: 3\n",
      "(Checkpoint ID: 1f10c2db-9062-6952-8000-b34c7f57e203) # of messages in state: 1\n",
      "(Checkpoint ID: 1f10c2db-9057-6c3d-bfff-5bd67fde8734) # of messages in state: 0\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in graph.get_state_history(config):\n",
    "    print(\n",
    "        f\"(Checkpoint ID: {checkpoint.config['configurable']['checkpoint_id']}) # of messages in state: {len(checkpoint.values.get('messages'))}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07194f-49b4-4fb9-a74b-d86b970cace6",
   "metadata": {},
   "source": [
    "### Testing Memory Persistence\n",
    "\n",
    "Now let's test the power of our checkpointer by continuing the conversation. The agent should remember our previous calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7117c6a-d1d5-4866-aee9-2b7229fd73fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='The first calculations you asked me to do were:\\n\\n1. **Multiply** 1337 times 515321\\n2. **Add** 412 to the result\\n\\nThese were part of your single request to calculate 1337 × 515321, then add 412 and return the final value.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '59c5c814-b0d9-4395-af2f-2c44f96ea17a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Feb 2026 18:23:37 GMT', 'content-type': 'application/json', 'content-length': '542', 'connection': 'keep-alive', 'x-amzn-requestid': '59c5c814-b0d9-4395-af2f-2c44f96ea17a'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1169]}, 'model_name': 'global.anthropic.claude-haiku-4-5-20251001-v1:0'}, id='run--95c19741-1c06-42ab-806d-8e4f3ed0c71a-0', usage_metadata={'input_tokens': 942, 'output_tokens': 70, 'total_tokens': 1012, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What were the first calculations I asked you to do?\"}]}\n",
    "\n",
    "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc602c5b-e6b3-4099-820a-a82266039849",
   "metadata": {},
   "source": [
    "### Starting a New Session\n",
    "\n",
    "Let's demonstrate session isolation by creating a new conversation thread. The agent won't remember the previous calculations in this new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ce88359-ee1e-44bd-9095-ad22b880dda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"I don't have any record of you asking me to multiply and add specific values in our conversation. This is the beginning of our chat, so you haven't made any such requests yet.\\n\\nWould you like me to multiply and add some numbers for you? If so, please provide the values you'd like me to work with!\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '5724b63f-5f52-4f78-a039-8fb95f81c755', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Feb 2026 18:23:44 GMT', 'content-type': 'application/json', 'content-length': '614', 'connection': 'keep-alive', 'x-amzn-requestid': '5724b63f-5f52-4f78-a039-8fb95f81c755'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1641]}, 'model_name': 'global.anthropic.claude-haiku-4-5-20251001-v1:0'}, id='run--87a23d52-c227-416a-9a42-200ce3185292-0', usage_metadata={'input_tokens': 653, 'output_tokens': 70, 'total_tokens': 723, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-2\", # New session ID\n",
    "        \"actor_id\": \"react-agent-1\", # Same Actor ID\n",
    "    }\n",
    "}\n",
    "\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What values did I ask you to multiply and add?\"}]}\n",
    "for chunk in graph.stream(inputs, stream_mode=\"updates\", config=config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7bd51-0ece-47d6-aae3-2a9041d98645",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "1. How to create an AgentCore Memory resource for checkpointing\n",
    "2. Building a LangGraph agent with automatic state persistence\n",
    "3. Implementing mathematical tools for multi-step calculations\n",
    "4. Using the AgentCoreMemorySaver as a checkpointer backend\n",
    "5. Testing memory persistence and session isolation\n",
    "\n",
    "This integration showcases the power of combining LangGraph's structured workflows with AgentCore Memory's robust checkpointing capabilities to create stateful, persistent AI agents that can maintain context across multiple interactions.\n",
    "\n",
    "The approach we've demonstrated can be extended to more complex use cases, including multi-agent systems, long-running workflows, and specialized state management based on conversation context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d2b47",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "Let's delete the memory to clean up the resources used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_memory_and_wait(memory_id = memory_id, max_wait = 300, poll_interval =10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
